{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354b1dec",
   "metadata": {},
   "source": [
    "# Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5260280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/930195603343704592', creation_time=1761403158123, experiment_id='930195603343704592', last_update_time=1761403158123, lifecycle_stage='active', name='DSPy Sentiment Analysis', tags={'mlflow.experimentKind': 'genai_development'}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is loaded\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully\")\n",
    "else:\n",
    "    print(\"API key not found in environment variables\")\n",
    "\n",
    "# Enable MLflow tracing for DSPy\n",
    "mlflow.dspy.autolog()\n",
    "\n",
    "# Optional: Set tracking URI and experiment name\n",
    "# Use local file storage instead of HTTP server for simplicity\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"DSPy Sentiment Analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7fed38",
   "metadata": {},
   "source": [
    "# Configure the LM (Language Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e881c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LM (Language Model) with structured output support\n",
    "lm = dspy.LM(\"openai/gpt-4o-mini\", model_type=\"chat\")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab224c6",
   "metadata": {},
   "source": [
    "## Use DSPy built-in Module to Build a Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a995231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(dspy.Signature):\n",
    "    \"\"\"Classify the sentiment of a text.\"\"\"\n",
    "\n",
    "    text: str = dspy.InputField(desc=\"input text to classify sentiment\")\n",
    "    sentiment: int = dspy.OutputField(\n",
    "        desc=\"sentiment, the higher the more positive\", ge=0, le=10\n",
    "    )\n",
    "\n",
    "# For my own notes: ge and le are pydantic constraints restricting the range of the sentiment output to be greater than or equal to: 0, less than or equal to: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e8a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_signature = dspy.make_signature(\"text -> sentiment\")\n",
    "\n",
    "# String based signature for the sentiment classifier (not recommended for production but good for testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea1b016",
   "metadata": {},
   "source": [
    "## Create a Module to Interact with the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0e07f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction successful!\n",
      "Text: 'I am feeling pretty happy about this!'\n",
      "Sentiment: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-1fc1149c8ec8e3b6b2b76b057de5cb21&amp;experiment_id=930195603343704592&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-1fc1149c8ec8e3b6b2b76b057de5cb21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the sentiment classifier\n",
    "try:\n",
    "    predict = dspy.Predict(SentimentClassifier)\n",
    "    output = predict(text=\"I am feeling pretty happy about this!\")\n",
    "    print(\"Prediction successful!\")\n",
    "    print(f\"Text: 'I am feeling pretty happy about this!'\")\n",
    "    print(f\"Sentiment: {output.sentiment}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(\"Please check your API key and internet connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716e33cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentiment classification with multiple examples:\n",
      "Text: 'I am feeling pretty happy about this!'\n",
      "Sentiment: 8/10\n",
      "........................................\n",
      "Text: 'This is terrible and I hate it.'\n",
      "Sentiment: 0/10\n",
      "........................................\n",
      "Text: 'I feel neutral about this situation.'\n",
      "Sentiment: 5/10\n",
      "........................................\n",
      "Text: 'I'm absolutely thrilled with the results!'\n",
      "Sentiment: 10/10\n",
      "........................................\n",
      "Text: 'This makes me so angry and frustrated.'\n",
      "Sentiment: 1/10\n",
      "........................................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-2b5f48e9394c1cd0376cf385562cb192&amp;experiment_id=930195603343704592&amp;trace_id=tr-8b4321ed8e5790929e091ef0a5718a3c&amp;experiment_id=930195603343704592&amp;trace_id=tr-1d30bc27800b72f0e3cff6223dbad7f1&amp;experiment_id=930195603343704592&amp;trace_id=tr-6f82d667c8b05cee3014fbe328f8810f&amp;experiment_id=930195603343704592&amp;trace_id=tr-adfdb4d8da815948c8a1a2bd5e62bb19&amp;experiment_id=930195603343704592&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-2b5f48e9394c1cd0376cf385562cb192), Trace(trace_id=tr-8b4321ed8e5790929e091ef0a5718a3c), Trace(trace_id=tr-1d30bc27800b72f0e3cff6223dbad7f1), Trace(trace_id=tr-6f82d667c8b05cee3014fbe328f8810f), Trace(trace_id=tr-adfdb4d8da815948c8a1a2bd5e62bb19)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with different sentiment examples\n",
    "test_texts = [\n",
    "    \"I am feeling pretty happy about this!\",\n",
    "    \"This is terrible and I hate it.\",\n",
    "    \"I feel neutral about this situation.\",\n",
    "    \"I'm absolutely thrilled with the results!\",\n",
    "    \"This makes me so angry and frustrated.\"\n",
    "]\n",
    "\n",
    "print(\"Testing sentiment classification with multiple examples:\")\n",
    "\n",
    "for text in test_texts:\n",
    "    try:\n",
    "        output = predict(text=text)\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"Sentiment: {output.sentiment}/10\")\n",
    "        print(\".\" * 40)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing '{text}': {e}\")\n",
    "        print(\".\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8082ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is: 1\n",
      "The sentiment is 1\n"
     ]
    }
   ],
   "source": [
    "# Alternative ways to view the output\n",
    "\n",
    "print(f\"The sentiment is: {output.sentiment}\")\n",
    "print(f\"The sentiment is {output['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6be668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sentiment=8\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-7b596f2c33e7b43651901bf7a4081b01&amp;experiment_id=930195603343704592&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-7b596f2c33e7b43651901bf7a4081b01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changing the LM use the dspy.configure() function\n",
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o\"))\n",
    "print(predict(text=\"I am feeling pretty happy!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0949a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa8f82",
   "metadata": {},
   "source": [
    "Where is my prompt?\n",
    "Check dspy.inspect_history(n=1) where n is how many entries you want to pull from the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0228e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-25T19:00:06.630033]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "Your output fields are:\n",
      "1. `sentiment` (int): sentiment, the higher the more positive\n",
      "Constraints: greater than or equal to: 0, less than or equal to: 10\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "{sentiment}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## sentiment ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## sentiment ## ]]\n",
      "8\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f29425",
   "metadata": {},
   "source": [
    "# Chain of Thought Built-in module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b125d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The text expresses a positive emotion, specifically happiness. The use of the word \"happy\" indicates a strong positive sentiment. Therefore, the sentiment score is high.',\n",
      "    sentiment=8\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-5b3c6a3d701c235b121cbc549b2a33e0&amp;experiment_id=930195603343704592&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-5b3c6a3d701c235b121cbc549b2a33e0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(SentimentClassifier)\n",
    "\n",
    "output = cot(text=\"I am feeling pretty happy!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e554e3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-25T19:00:06.801904]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `sentiment` (int): sentiment, the higher the more positive\n",
      "Constraints: greater than or equal to: 0, less than or equal to: 10\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "{sentiment}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sentiment ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The text expresses a positive emotion, specifically happiness. The use of the word \"happy\" indicates a strong positive sentiment. Therefore, the sentiment score is high.\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "8\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8babc42a",
   "metadata": {},
   "source": [
    "## Using a different Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9b9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.configure(adapter=dspy.JSONAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1fd80db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The text expresses a positive emotion, specifically happiness, which indicates a strong positive sentiment.',\n",
      "    sentiment=8\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-25T19:00:06.957753]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `sentiment` (int): sentiment, the higher the more positive\n",
      "Constraints: greater than or equal to: 0, less than or equal to: 10\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"sentiment\": \"{sentiment}        # note: the value you produce must be a single int value\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `sentiment` (must be formatted as a valid Python int).\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\"reasoning\":\"The text expresses a positive emotion, specifically happiness, which indicates a strong positive sentiment.\",\"sentiment\":8}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-e0c7ac3594cca5b2fbe3f6c5b46eb4c9&amp;experiment_id=930195603343704592&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-e0c7ac3594cca5b2fbe3f6c5b46eb4c9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cot(text=\"I am feeling pretty happy!\"))\n",
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02acb429",
   "metadata": {},
   "source": [
    "## Building a Program with Custom Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c04431d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionGenerator(dspy.Signature):\n",
    "    \"\"\"Genereate a yes or no question in order to guess the celebrity name\"\"\"\n",
    "    past_questions: list[str] = dspy.InputField(desc=\"past questions asked\")\n",
    "    past_answers: list[bool] = dspy.InputField(desc=\"past answers\")\n",
    "    new_question: str = dspy.OutputField(desc=\"new question that can help guess the celebrity name\")\n",
    "    guess_made: bool = dspy.OutputField(desc=\"If the new_question is a good guess\")\n",
    "\n",
    "class Reflection(dspy.Signature):\n",
    "    \"\"\"Provide reflection on the guessing process\"\"\"\n",
    "    correct_celebrity_name: str = dspy.InputField(desc=\"the correct celebrity name\")\n",
    "    final_guessor_question: str = dspy.InputField(desc=\"the final guess question asked\")\n",
    "    past_questions: list[str] = dspy.InputField(desc=\"past questions asked\")\n",
    "    past_answers: list[bool] = dspy.InputField(desc=\"past answers\")\n",
    "\n",
    "    reflection: str = dspy.OutputField(\n",
    "        desc=\"reflection on the guessing process, including what was learned\"\n",
    "    )\n",
    "\n",
    "def ask(prompt, valid_responses=(\"y\", \"n\")):\n",
    "    while True:\n",
    "        response = input(f\"{prompt} ({'/'.join(valid_responses)}): \").lower()\n",
    "        if response in valid_responses:\n",
    "            return response\n",
    "        print(f\"Please enter one of: {', '.join(valid_responses)}\")\n",
    "\n",
    "class CelebrityGuess(dspy.Module):\n",
    "    def __init__(self, max_tries=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.question_generator = dspy.ChainOfThought(QuestionGenerator)\n",
    "        self.reflection = dspy.ChainOfThought(Reflection)\n",
    "\n",
    "        self.max_tries = 20\n",
    "\n",
    "    def forward(self):\n",
    "        # Start MLflow run for tracking this execution\n",
    "        start_time = time.time()\n",
    "        run_name = f\"celebrity_guess_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        with mlflow.start_run(run_name=run_name, description=\"Interactive celebrity guessing game execution\") as run:\n",
    "            # Log initial parameters\n",
    "            mlflow.log_param(\"max_tries\", self.max_tries)\n",
    "            mlflow.log_param(\"module_type\", \"celebrity_guess\")\n",
    "            mlflow.log_param(\"question_generator_signature\", \"QuestionGenerator\")\n",
    "            mlflow.log_param(\"reflection_signature\", \"Reflection\")\n",
    "            \n",
    "            celebrity_name = input(\"Please think of a celebrity name, once you are ready, type the name and press enter...\")\n",
    "            past_questions = []\n",
    "            past_answers = []\n",
    "\n",
    "            correct_guess = False\n",
    "            actual_attempts = 0\n",
    "\n",
    "            # Log initial state\n",
    "            mlflow.log_param(\"target_celebrity\", celebrity_name)\n",
    "\n",
    "            for i in range(self.max_tries):\n",
    "                actual_attempts = i + 1\n",
    "                \n",
    "                try:\n",
    "                    # Generate question with MLflow tracking\n",
    "                    question = self.question_generator(\n",
    "                        past_questions=past_questions,\n",
    "                        past_answers=past_answers,\n",
    "                    )\n",
    "                    \n",
    "                    # Log question generation details\n",
    "                    mlflow.log_metric(f\"question_{i+1}_generated\", 1)\n",
    "                    mlflow.log_param(f\"question_{i+1}_text\", question.new_question)\n",
    "                    mlflow.log_param(f\"question_{i+1}_guess_made\", question.guess_made)\n",
    "                    \n",
    "                    # Get user answer\n",
    "                    answer = ask(f\"{question.new_question}\").lower() == \"y\"\n",
    "                    past_questions.append(question.new_question)\n",
    "                    past_answers.append(answer)\n",
    "\n",
    "                    # Log user interaction\n",
    "                    mlflow.log_metric(f\"attempt_{i+1}_user_answer\", 1 if answer else 0)\n",
    "                    mlflow.log_param(f\"attempt_{i+1}_question\", question.new_question)\n",
    "                    mlflow.log_param(f\"attempt_{i+1}_answer\", answer)\n",
    "\n",
    "                    # Check for correct guess\n",
    "                    if question.guess_made and answer:\n",
    "                        correct_guess = True\n",
    "                        mlflow.log_metric(\"final_attempt_number\", actual_attempts)\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Log errors\n",
    "                    mlflow.log_param(\"error_occurred\", True)\n",
    "                    mlflow.log_param(\"error_message\", str(e))\n",
    "                    mlflow.log_param(\"error_attempt\", i + 1)\n",
    "                    mlflow.set_tag(\"execution_status\", \"failed\")\n",
    "                    print(f\"Error during attempt {i+1}: {e}\")\n",
    "                    break\n",
    "\n",
    "            # Calculate execution metrics\n",
    "            execution_time = time.time() - start_time\n",
    "\n",
    "            if correct_guess:\n",
    "                print(\"Yay! I got it right!\")\n",
    "                outcome = \"success\"\n",
    "                mlflow.log_metric(\"success\", 1)\n",
    "            else:\n",
    "                print(\"Oops, I couldn't guess it right.\")\n",
    "                outcome = \"failed\"\n",
    "                mlflow.log_metric(\"success\", 0)\n",
    "\n",
    "            # Generate reflection\n",
    "            try:\n",
    "                reflection = self.reflection(\n",
    "                    correct_celebrity_name=celebrity_name,\n",
    "                    final_guessor_question=question.new_question if 'question' in locals() else \"No final question\",\n",
    "                    past_questions=past_questions,\n",
    "                    past_answers=past_answers,\n",
    "                )\n",
    "                reflection_text = reflection.reflection\n",
    "                \n",
    "                # Log reflection details\n",
    "                mlflow.log_param(\"reflection_generated\", True)\n",
    "                mlflow.log_param(\"reflection_text\", reflection_text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                reflection_text = f\"Failed to generate reflection: {e}\"\n",
    "                mlflow.log_param(\"reflection_generated\", False)\n",
    "                mlflow.log_param(\"reflection_error\", str(e))\n",
    "\n",
    "            print(reflection_text)\n",
    "\n",
    "            # Log comprehensive metrics\n",
    "            mlflow.log_metric(\"execution_time_seconds\", execution_time)\n",
    "            mlflow.log_metric(\"actual_attempts\", actual_attempts)\n",
    "            mlflow.log_metric(\"total_questions_asked\", len(past_questions))\n",
    "            mlflow.log_metric(\"efficiency_ratio\", actual_attempts / self.max_tries if self.max_tries > 0 else 0)\n",
    "            mlflow.log_metric(\"questions_per_attempt\", len(past_questions) / max(actual_attempts, 1))\n",
    "\n",
    "            # Log conversation data as artifacts\n",
    "            conversation_data = {\n",
    "                \"celebrity_name\": celebrity_name,\n",
    "                \"outcome\": outcome,\n",
    "                \"actual_attempts\": actual_attempts,\n",
    "                \"max_tries\": self.max_tries,\n",
    "                \"execution_time_seconds\": execution_time,\n",
    "                \"success\": correct_guess,\n",
    "                \"past_questions\": past_questions,\n",
    "                \"past_answers\": past_answers,\n",
    "                \"final_question\": question.new_question if 'question' in locals() else None,\n",
    "                \"final_answer\": answer if 'answer' in locals() else None,\n",
    "                \"reflection\": reflection_text,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"run_id\": run.info.run_id\n",
    "            }\n",
    "\n",
    "            # Save as JSON artifact\n",
    "            with open(\"celebrity_guess_results.json\", \"w\") as f:\n",
    "                json.dump(conversation_data, f, indent=2)\n",
    "            mlflow.log_artifact(\"celebrity_guess_results.json\")\n",
    "\n",
    "            # Save conversation log as text artifact\n",
    "            conversation_log = f\"... Celebrity Guessing Game ...\\n\"\n",
    "            conversation_log += f\"Target Celebrity: {celebrity_name}\\n\"\n",
    "            conversation_log += f\"Outcome: {'SUCCESS' if correct_guess else 'FAILED'}\\n\"\n",
    "            conversation_log += f\"Attempts Used: {actual_attempts}/{self.max_tries}\\n\"\n",
    "            conversation_log += f\"Execution Time: {execution_time:.2f} seconds\\n\"\n",
    "            conversation_log += f\"Questions Asked: {len(past_questions)}\\n\\n\"\n",
    "            \n",
    "            conversation_log += \"... Question History ...\\n\"\n",
    "            for i, (q, a) in enumerate(zip(past_questions, past_answers)):\n",
    "                status = \"✓\" if (i == len(past_questions) - 1 and correct_guess) else \"→\"\n",
    "                conversation_log += f\"{i+1}. {status} {q}\\n\"\n",
    "                conversation_log += f\"   Answer: {'Yes' if a else 'No'}\\n\\n\"\n",
    "            \n",
    "            conversation_log += f\"... Final Reflection ...\\n{reflection_text}\\n\"\n",
    "            \n",
    "            with open(\"celebrity_guess_conversation.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(conversation_log)\n",
    "            mlflow.log_artifact(\"celebrity_guess_conversation.txt\")\n",
    "\n",
    "            # Set tags for easy filtering\n",
    "            mlflow.set_tag(\"execution_status\", \"completed\")\n",
    "            mlflow.set_tag(\"outcome\", outcome)\n",
    "            mlflow.set_tag(\"celebrity_category\", self._categorize_celebrity(celebrity_name))\n",
    "            mlflow.set_tag(\"attempts_category\", self._categorize_attempts(actual_attempts))\n",
    "\n",
    "            # Log final summary metrics\n",
    "            mlflow.log_metric(\"completion_rate\", 1.0 if correct_guess else 0.0)\n",
    "            mlflow.log_metric(\"average_time_per_attempt\", execution_time / max(actual_attempts, 1))\n",
    "\n",
    "        return {\n",
    "            \"celebrity_name\": celebrity_name,\n",
    "            \"success\": correct_guess,\n",
    "            \"attempts\": actual_attempts,\n",
    "            \"execution_time\": execution_time,\n",
    "            \"reflection\": reflection_text,\n",
    "            \"run_id\": run.info.run_id if 'run' in locals() else None\n",
    "        }\n",
    "\n",
    "    def _categorize_celebrity(self, celebrity_name):\n",
    "        \"\"\"Categorize celebrity for analysis\"\"\"\n",
    "        celebrity_lower = celebrity_name.lower()\n",
    "        if any(word in celebrity_lower for word in ['actor', 'actress', 'director', 'film', 'movie']):\n",
    "            return \"entertainment\"\n",
    "        elif any(word in celebrity_lower for word in ['singer', 'musician', 'rapper', 'band', 'music']):\n",
    "            return \"music\"\n",
    "        elif any(word in celebrity_lower for word in ['player', 'coach', 'team', 'sport', 'nba', 'football']):\n",
    "            return \"sports\"\n",
    "        elif any(word in celebrity_lower for word in ['president', 'politician', 'leader', 'minister']):\n",
    "            return \"politics\"\n",
    "        else:\n",
    "            return \"other\"\n",
    "\n",
    "    def _categorize_attempts(self, attempts):\n",
    "        \"\"\"Categorize attempts for performance analysis\"\"\"\n",
    "        if attempts <= 3:\n",
    "            return \"excellent\"\n",
    "        elif attempts <= 7:\n",
    "            return \"good\"\n",
    "        elif attempts <= 12:\n",
    "            return \"average\"\n",
    "        else:\n",
    "            return \"poor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1250981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_generator.predict = Predict(StringSignature(past_questions, past_answers -> reasoning, new_question, guess_made\n",
       "    instructions='Genereate a yes or no question in order to guess the celebrity name'\n",
       "    past_questions = Field(annotation=list[str] required=True json_schema_extra={'desc': 'past questions asked', '__dspy_field_type': 'input', 'prefix': 'Past Questions:'})\n",
       "    past_answers = Field(annotation=list[bool] required=True json_schema_extra={'desc': 'past answers', '__dspy_field_type': 'input', 'prefix': 'Past Answers:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    new_question = Field(annotation=str required=True json_schema_extra={'desc': 'new question that can help guess the celebrity name', '__dspy_field_type': 'output', 'prefix': 'New Question:'})\n",
       "    guess_made = Field(annotation=bool required=True json_schema_extra={'desc': 'If the new_question is a good guess', '__dspy_field_type': 'output', 'prefix': 'Guess Made:'})\n",
       "))\n",
       "reflection.predict = Predict(StringSignature(correct_celebrity_name, final_guessor_question, past_questions, past_answers -> reasoning, reflection\n",
       "    instructions='Provide reflection on the guessing process'\n",
       "    correct_celebrity_name = Field(annotation=str required=True json_schema_extra={'desc': 'the correct celebrity name', '__dspy_field_type': 'input', 'prefix': 'Correct Celebrity Name:'})\n",
       "    final_guessor_question = Field(annotation=str required=True json_schema_extra={'desc': 'the final guess question asked', '__dspy_field_type': 'input', 'prefix': 'Final Guessor Question:'})\n",
       "    past_questions = Field(annotation=list[str] required=True json_schema_extra={'desc': 'past questions asked', '__dspy_field_type': 'input', 'prefix': 'Past Questions:'})\n",
       "    past_answers = Field(annotation=list[bool] required=True json_schema_extra={'desc': 'past answers', '__dspy_field_type': 'input', 'prefix': 'Past Answers:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    reflection = Field(annotation=str required=True json_schema_extra={'desc': 'reflection on the guessing process, including what was learned', '__dspy_field_type': 'output', 'prefix': 'Reflection:'})\n",
       "))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celebrity_guess = CelebrityGuess()\n",
    "celebrity_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc590219",
   "metadata": {},
   "source": [
    "## Save and Load using dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0363446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_guess.save(\"dspy_program/celebrity.json\", save_program=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e864ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_guess.load(\"dspy_program/celebrity.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f9e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_guess.save(\"dspy_program/celebrity/\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12c57604",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = dspy.load(\"dspy_program/celebrity/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d1d95ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay! I got it right!\n",
      "This guessing process highlighted the importance of asking targeted questions that progressively narrow down the options. Each question built upon the previous answers, allowing for a logical deduction of the celebrity's identity. I learned that focusing on specific attributes, such as the sport and team, can significantly streamline the guessing process.\n",
      "🏃 View run celebrity_guess_20251025_190007 at: http://localhost:5000/#/experiments/930195603343704592/runs/d0e6153dcb364912a493fa2018761c32\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/930195603343704592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'celebrity_name': 'Lebron James',\n",
       " 'success': True,\n",
       " 'attempts': 7,\n",
       " 'execution_time': 29.56076169013977,\n",
       " 'reflection': \"This guessing process highlighted the importance of asking targeted questions that progressively narrow down the options. Each question built upon the previous answers, allowing for a logical deduction of the celebrity's identity. I learned that focusing on specific attributes, such as the sport and team, can significantly streamline the guessing process.\",\n",
       " 'run_id': 'd0e6153dcb364912a493fa2018761c32'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-ac0f3a8d59092379c6af9077015ed141&amp;experiment_id=930195603343704592&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-ac0f3a8d59092379c6af9077015ed141)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c743274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-25T19:00:36.842608]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `correct_celebrity_name` (str): the correct celebrity name\n",
      "2. `final_guessor_question` (str): the final guess question asked\n",
      "3. `past_questions` (list[str]): past questions asked\n",
      "4. `past_answers` (list[bool]): past answers\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `reflection` (str): reflection on the guessing process, including what was learned\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## correct_celebrity_name ## ]]\n",
      "{correct_celebrity_name}\n",
      "\n",
      "[[ ## final_guessor_question ## ]]\n",
      "{final_guessor_question}\n",
      "\n",
      "[[ ## past_questions ## ]]\n",
      "{past_questions}\n",
      "\n",
      "[[ ## past_answers ## ]]\n",
      "{past_answers}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"reflection\": \"{reflection}\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        Provide reflection on the guessing process\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## correct_celebrity_name ## ]]\n",
      "Lebron James\n",
      "\n",
      "[[ ## final_guessor_question ## ]]\n",
      "Is the celebrity LeBron James?\n",
      "\n",
      "[[ ## past_questions ## ]]\n",
      "[\"Is the celebrity an actor?\", \"Is the celebrity a musician?\", \"Is the celebrity an athlete?\", \"Is the athlete known for playing basketball?\", \"Is the athlete currently active in the NBA?\", \"Does the athlete play for the Los Angeles Lakers?\", \"Is the celebrity LeBron James?\"]\n",
      "\n",
      "[[ ## past_answers ## ]]\n",
      "[false, false, true, true, true, true, true]\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `reflection`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\"reasoning\":\"The final guess was correct because the previous questions narrowed down the possibilities effectively. The questions established that the celebrity was an athlete, specifically a basketball player, and that they were currently active in the NBA and played for the Los Angeles Lakers. This process of elimination led directly to the conclusion that the celebrity in question was LeBron James.\",\"reflection\":\"This guessing process highlighted the importance of asking targeted questions that progressively narrow down the options. Each question built upon the previous answers, allowing for a logical deduction of the celebrity's identity. I learned that focusing on specific attributes, such as the sport and team, can significantly streamline the guessing process.\"}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
